{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LEukXWQfiic"
   },
   "source": [
    "# Supervised/unsupervised Sentiment and Topic analysis. <br>\r\n",
    "\r\n",
    "### Final project assignment. <br>\r\n",
    "\r\n",
    "Introduction  to Natural Language Processing (NLP) \r\n",
    "(DSCI-D590-31731)\r\n",
    "\r\n",
    "Anitha Ganapathy | aganapa@iu.edu <br>\r\n",
    "12/01/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_05_ihyhev9",
    "outputId": "aacac3bc-7266-406c-9fdf-d6d1dd127892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 17 00:17:28 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.81       Driver Version: 456.81       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX150      WDDM  | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   50C    P8    N/A /  N/A |     64MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zFiQbA8BhySd"
   },
   "outputs": [],
   "source": [
    "# !nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uR8qyu5QtfoJ"
   },
   "outputs": [],
   "source": [
    "# !pip install docx2txt\r\n",
    "# !pip install tensorflow_text\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRrILjyvgk-z"
   },
   "source": [
    "Organizing imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Nyp4zOGShcGq"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-496d294062fb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mnltk\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\r\n",
    "import os\r\n",
    "import sys\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import re\r\n",
    "import nltk\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.colors as mcolors\r\n",
    "import docx2txt\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_hub as hub\r\n",
    "import tensorflow_text\r\n",
    "import seaborn as sns\r\n",
    "import gensim\r\n",
    "import json\r\n",
    "import datetime\r\n",
    "\r\n",
    "from tqdm import tqdm\r\n",
    "from nltk import word_tokenize\r\n",
    "from collections import Counter\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk import WordPunctTokenizer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\r\n",
    "from nltk import wordnet\r\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\r\n",
    "from tensorflow import keras\r\n",
    "from keras.preprocessing.text import Tokenizer\r\n",
    "from keras.preprocessing.sequence import pad_sequences\r\n",
    "from keras.models import Model, Sequential\r\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\r\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\r\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\r\n",
    "from keras.callbacks import Callback, ModelCheckpoint\r\n",
    "from keras.preprocessing import text, sequence\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from keras.utils import to_categorical\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.manifold import TSNE\r\n",
    "from gensim.models import word2vec\r\n",
    "from pylab import rcParams\r\n",
    "from pandas.plotting import register_matplotlib_converters\r\n",
    "\r\n",
    "# plt.style.use('ggplot')\r\n",
    "%config InlineBackend.figure_format='retina'\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "import warnings \r\n",
    "warnings.filterwarnings('ignore')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yCQaURqWI_e",
    "outputId": "715ed7a2-3c4c-4210-c5b7-cb08ac7c1375"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3tdfgiO01_J"
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 12, 8\r\n",
    "RANDOM_SEED = 2000737430\r\n",
    "np.random.seed(RANDOM_SEED)\r\n",
    "tf.random.set_seed(RANDOM_SEED)\r\n",
    "\r\n",
    "register_matplotlib_converters()\r\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\r\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\r\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXQ_C5lT0Mz3",
    "outputId": "649af178-ec2d-436e-b5cc-81d61dbc889e"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"../content\"))\r\n",
    "print(f'Python version     : {sys.version}')\r\n",
    "print(f'Pandas version     : {pd.__version__}')\r\n",
    "print(f'Numpy version      : {np.__version__}')\r\n",
    "print(f'Tensorflow version : {tf.__version__}')\r\n",
    "print(f'NLTK version       : {nltk.__version__}')\r\n",
    "print(f'Regex version      : {re.__version__}')\r\n",
    "print(\"GPU Device name: \",tf.config.list_physical_devices('GPU'))\r\n",
    "# print(\"\\nCheck if GPU is available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRzOlM9Tp0W3"
   },
   "source": [
    "**Dataset**\r\n",
    "The data I am using for the assignment is the Amazon Fine Food Reviews. <br>\r\n",
    "https://www.kaggle.com/snap/amazon-fine-food-reviews\r\n",
    " \r\n",
    "\r\n",
    "**Data Reference:**\r\n",
    "\r\n",
    "J. McAuley and J. Leskovec. From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews. WWW, 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eT94gCDyjTW1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Amazon Fine Food Reviews.csv\", parse_dates= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRT5GtZ3xldh"
   },
   "source": [
    "## Step 1 :  Describe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-alkcy1toaDq",
    "outputId": "2482cf39-d14d-4b25-8508-34f0cad86b7f"
   },
   "outputs": [],
   "source": [
    "print(\"The Amazon Fine Food Reviews dataset brief:\")\r\n",
    "print(\"\\nNumber of reviews:\", df.shape[0])\r\n",
    "print(\"Number of users: \", len(df.UserId.unique()))\r\n",
    "print(\"Number of products: \", len(df.ProductId.unique()) )\r\n",
    "print(\"Number of Attributes/Columns in data: \", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C86ae7PWyCHV"
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16vHj4Wjwp8W"
   },
   "source": [
    "The column or features in the dataset: <br>\r\n",
    "*   Id <br>\r\n",
    "*   ProductId — unique identifier for the product <br>\r\n",
    "*   UserId — unqiue identifier for the user\r\n",
    "*   ProfileName <br>\r\n",
    "*   HelpfulnessNumerator — number of users who found the review helpful <br>\r\n",
    "*   HelpfulnessDenominator — number of users who indicated whether they found the review helpful or not <br>\r\n",
    "*   Score — rating between 1 and 5 <br>\r\n",
    "*   Time — timestamp for the review <br>\r\n",
    "*   Summary — brief summary of the review <br>\r\n",
    "*   Text — text of the review <br>\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koE5ID4J7Kgm",
    "outputId": "46497bd2-9c7d-4ee0-cf24-b9d92a2d08f6"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "WPHAt7h67QYz",
    "outputId": "0189e958-9bd5-4c96-9701-503a3e17d82a"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zx_psm57U2ic"
   },
   "source": [
    "Checking for NAN values in the dataset. Nan values in the text column provided difficulty in plotting the wordcloud.\r\n",
    "So replaced the nan with empty string.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KsYannw6yX-",
    "outputId": "8d291bd6-ee8d-455c-c281-e78396d73087"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rInDVUry85jE"
   },
   "source": [
    "## Step 2: Perform data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_skvslvWubrh",
    "outputId": "af87c416-66b5-42e2-ee4d-2e75fa907cc3"
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"Amazon Fine Food Reviews.csv\", parse_dates= True)\r\n",
    "\r\n",
    "df_old = df\r\n",
    "df.Summary = df.Summary.fillna('')       # replacing the NAN with ''\r\n",
    "df['review'] = df['Summary'] + df['Text']\r\n",
    "df.isna().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "fUgff7Z-9SlK",
    "outputId": "b42c78b6-7f0b-4160-8f3f-cf4b4a3f0ae8"
   },
   "outputs": [],
   "source": [
    "df = df[['Score', 'review']]\r\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXN7bp2Y9ZTo",
    "outputId": "5af6196f-bf9c-4c8d-e6af-79caab3a62b5"
   },
   "outputs": [],
   "source": [
    "df.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhKmSnOLS9Ro",
    "outputId": "0d8c610a-ff92-4d24-b99e-e8e8ca61e820"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qd7lkwQ5wtjS"
   },
   "source": [
    "### Analysing the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "id": "0yjCP4mV06do",
    "outputId": "4c12f14c-3ac2-4a34-e111-d024c3f9b90b"
   },
   "outputs": [],
   "source": [
    "# sns.countplot(df['Score'], order=df.Score.value_counts().index)\r\n",
    "sns.countplot(df['Score'])\r\n",
    "fig = plt.gcf()\r\n",
    "fig.set_size_inches(10,10)\r\n",
    "plt.title('Amazon Food and Wine Reviews.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pk0fz3PV1Mj7"
   },
   "source": [
    "Just for simplicity and because we need more data for the binary classification of Good or Bad reviews, we shall consider a rating of 3 or less as bad reviews and a rating of 4 and more as good reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUNcv9FnJjhB"
   },
   "outputs": [],
   "source": [
    "# Give reviews with Score > 3 a positive rating('good), \r\n",
    "# and reviews with a score<=3 a negative review_type('bad').\r\n",
    "\r\n",
    "df[\"review_type\"] = df[\"Score\"].apply(lambda x: \"negative\" if x <= 3 else \"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aAVHiAE99_m0",
    "outputId": "5a3a9acb-53ed-4ef7-d54e-3bfb242bdd84"
   },
   "outputs": [],
   "source": [
    "df.review_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "jgbtPerv0X89",
    "outputId": "a9123f98-2128-4803-bbfe-3bd5b186ad2d"
   },
   "outputs": [],
   "source": [
    "sns.countplot(\r\n",
    "  x='review_type',\r\n",
    "  data=df,\r\n",
    "  order=df.review_type.value_counts().index\r\n",
    ")\r\n",
    "plt.xlabel(\"type\")\r\n",
    "plt.title(\"Review type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDPf0nY61w6C",
    "outputId": "22c86c3f-9b9c-4936-c8b3-a8e9e09e8b0c"
   },
   "outputs": [],
   "source": [
    "positive_reviews = df[df.review_type == \"positive\"]\r\n",
    "negative_reviews = df[df.review_type == \"negative\"]\r\n",
    "\r\n",
    "print(\"Good reviews shape: \",positive_reviews.shape)\r\n",
    "print(\"Bad reviews shape: \", negative_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C23mSvEg2Ks5"
   },
   "source": [
    "We need the good and bad reviews to have same review counts, so we will take equal amout of good reviews as bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9fUqEmx2rri"
   },
   "outputs": [],
   "source": [
    "positive_reviews_text = \" \".join(positive_reviews.review.to_numpy().tolist())\r\n",
    "negative_reviews_text = \" \".join(negative_reviews.review.to_numpy().tolist())\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_IOOszCU3lf"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "wpt = nltk.WordPunctTokenizer()\r\n",
    "stop_words = nltk.corpus.stopwords.words('english')\r\n",
    "def normalize_document(doc):\r\n",
    "    # lowercase and remove special characters\\whitespace\r\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, flags =re.I)\r\n",
    "    doc = doc.lower()\r\n",
    "    doc = doc.strip()\r\n",
    "    # tokenize document\r\n",
    "    tokens = wpt.tokenize(doc)\r\n",
    "    # filter stopwords out of document\r\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\r\n",
    "    # re-create document from filtered tokens\r\n",
    "    doc = ' '.join(filtered_tokens)\r\n",
    "    return doc\r\n",
    "  \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNunMMMXVdsH"
   },
   "outputs": [],
   "source": [
    "positive_normalize_text = normalize_document(positive_reviews_text)\r\n",
    "negative_normalize_text = normalize_document(negative_reviews_text)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PehPDOLVUSjs"
   },
   "outputs": [],
   "source": [
    "datetime.datetime.now()\r\n",
    "positive_reviews_cloud = WordCloud(stopwords=STOPWORDS,background_color=\"black\").generate(positive_normalize_text)\r\n",
    "negative_reviews_cloud = WordCloud(stopwords=STOPWORDS, background_color=\"black\").generate(negative_normalize_text)\r\n",
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7c69sfOXAz-",
    "outputId": "e80a77d2-5421-4b1f-80c5-8a34f0e62291"
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())\r\n",
    "def show_word_cloud(cloud, title):\r\n",
    "  plt.figure(figsize = (20, 20))\r\n",
    "  plt.imshow(cloud, interpolation='bilinear')\r\n",
    "  plt.title(title)\r\n",
    "  plt.axis(\"off\")\r\n",
    "  plt.show()\r\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jv-AhDuUrCEB"
   },
   "source": [
    "## Step 3: Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "G9I0G2zDXDSB",
    "outputId": "729a1665-cec8-49a0-b468-465bc3ba8d80"
   },
   "outputs": [],
   "source": [
    "show_word_cloud(positive_reviews_cloud, \"Positive Reviews cloud display.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "HMgcMAUdXSB1",
    "outputId": "3fe6e5f9-8d69-4b30-cf97-068b71fa957d"
   },
   "outputs": [],
   "source": [
    "show_word_cloud(negative_reviews_cloud, \"Negative Reviews cloud display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyxcmfOfY3MB"
   },
   "source": [
    "We’ll deal with the review type count imbalance by sampling the number of good ones to that of the bad ones. We need same amount of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfk0X0FbY17K"
   },
   "outputs": [],
   "source": [
    "positive_df = positive_reviews.sample(n=len(negative_reviews), random_state=RANDOM_SEED)\r\n",
    "negative_df = negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3a5EWvlZYqF",
    "outputId": "91f082b0-e666-4b4c-ed76-dfc5df9d74c7"
   },
   "outputs": [],
   "source": [
    "review_df = positive_df.append(negative_df).reset_index(drop=True)\r\n",
    "print(\"Final review data df shape: \", review_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "mgo_YOBnZvvU",
    "outputId": "5f57b307-bb9a-4f6f-f7a1-3da2bc5e0bf2"
   },
   "outputs": [],
   "source": [
    "sns.countplot(\r\n",
    "  x='review_type',\r\n",
    "  data=review_df,\r\n",
    "  order=review_df.review_type.value_counts().index\r\n",
    ")\r\n",
    "\r\n",
    "plt.xlabel(\"type\")\r\n",
    "plt.title(\"Review type (resampled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-3dc9Z7lndA"
   },
   "source": [
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXvMZRACtM8I"
   },
   "source": [
    "google/universal-sentence-encoder/4 - a much larger model yielding 512 dimensional embeddings trained with a deep averaging network (DAN) encoder.\r\n",
    "\r\n",
    "The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering, and other natural language tasks.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22uRwaLos2G6",
    "outputId": "eff5a83d-e1cb-4cbd-fa11-b977d40cbfec"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\r\n",
    "\r\n",
    "# it took 14 mins to load this module\r\n",
    "\r\n",
    "print(datetime.datetime.now())\r\n",
    "use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\r\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQ5WEDqcbe_C",
    "outputId": "ce4aad9a-7f92-4603-852d-29a339a53a4b"
   },
   "outputs": [],
   "source": [
    "sent_1 = [\"the location is great\"]\r\n",
    "sent_2 = [\"amazing location\"]\r\n",
    "\r\n",
    "emb_1 = use(sent_1)\r\n",
    "emb_2 = use(sent_2)\r\n",
    "emb_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKfe4WtPbjEX",
    "outputId": "b805cb61-94d1-4449-ffd9-15a6378050b5"
   },
   "outputs": [],
   "source": [
    "np.inner(emb_1, emb_2).flatten()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TctdUY_d85Ax"
   },
   "source": [
    "## Step 4. Splitting data into training and testing.\r\n",
    "Split in 80-20 training or UseCross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHRU0xCAW_I_"
   },
   "outputs": [],
   "source": [
    "type_one_hot = OneHotEncoder(sparse=False).fit_transform(\r\n",
    "  review_df.review_type.to_numpy().reshape(-1, 1)\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qyCXHRr9QYa"
   },
   "outputs": [],
   "source": [
    "train_reviews, test_reviews, y_train, y_test =\\\r\n",
    "  train_test_split(\r\n",
    "    review_df.review, \r\n",
    "    type_one_hot, \r\n",
    "    test_size=.2, \r\n",
    "    random_state=RANDOM_SEED\r\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KMXOiuUz8QE"
   },
   "source": [
    "## Step 5: Perform data vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPQQeR1FD1D1",
    "outputId": "f54c8006-3904-45aa-ecaa-ade4fefe4d39"
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())\r\n",
    "X_train = []\r\n",
    "for r in tqdm(train_reviews):\r\n",
    "  embedded = use(r)\r\n",
    "  review_emb = tf.reshape(embedded, [-1]).numpy()\r\n",
    "  X_train.append(review_emb)\r\n",
    "\r\n",
    "X_train = np.array(X_train)\r\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5BzX9NJ-AWj",
    "outputId": "4360a30c-4a79-417a-b92a-1e7a6d4a767e"
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())\r\n",
    "X_test = []\r\n",
    "for r in tqdm(test_reviews):\r\n",
    "  emb = use(r)\r\n",
    "  review_emb = tf.reshape(emb, [-1]).numpy()\r\n",
    "  X_test.append(review_emb)\r\n",
    "\r\n",
    "X_test = np.array(X_test)\r\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1I_blhpm-Re",
    "outputId": "89c18efa-bf6d-435b-aaa3-7a35ac07189b"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xcStV7FnBsF",
    "outputId": "62ae836e-4c01-44e1-d1ae-52d353e658d9"
   },
   "outputs": [],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5h2OdN40JcZ"
   },
   "source": [
    "## Step 6: Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGy8L3kt0wt-"
   },
   "source": [
    "Sentiment Analysis is a binary classification problem. Let’s use Keras to build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7khIYtPlnD0x",
    "outputId": "a5ba95bc-502a-4e06-c6e6-f0d1974b1095"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\r\n",
    "\r\n",
    "model.add(keras.layers.Dense(units=256, input_shape=(X_train.shape[1], ), activation='relu'))\r\n",
    "model.add(keras.layers.Dropout(rate=0.2))\r\n",
    "model.add(keras.layers.Dense(units=128, activation='relu'))\r\n",
    "model.add(keras.layers.Dropout(rate=0.2))\r\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\r\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy'])\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjLzqRFI3Rrs"
   },
   "source": [
    "The model is composed of 2 fully-connected hidden layers. Dropout is used for regularization.\r\n",
    "\r\n",
    "We’ll train for 15 epochs and use 10% of the data for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31ESxqDEnKCM",
    "outputId": "0ee64afc-d5c7-4a41-9b6c-929d4019bcfb"
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())\r\n",
    "\r\n",
    "history = model.fit(\r\n",
    "    X_train, y_train, \r\n",
    "    epochs=15, \r\n",
    "    batch_size=16, \r\n",
    "    validation_split=0.1, \r\n",
    "    verbose=1, \r\n",
    "    shuffle=True\r\n",
    ")\r\n",
    "\r\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "vkcz8Jh1nN8P",
    "outputId": "ae27909e-5963-417d-bcd4-0fdf99d229c8"
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 12, 8\r\n",
    "plt.plot(history.history['loss'], label='train loss')\r\n",
    "plt.plot(history.history['val_loss'], label='val loss')\r\n",
    "plt.xlabel(\"epoch\")\r\n",
    "plt.ylabel(\"Cross-entropy loss\")\r\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "Moq6_NKFnRq9",
    "outputId": "95690424-d8fa-441e-e9c6-35f1800320fb"
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 12, 8\r\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\r\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\r\n",
    "plt.xlabel(\"epoch\")\r\n",
    "plt.ylabel(\"accuracy\")\r\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHdZSj62CNln",
    "outputId": "ad6a861f-01bc-4220-bb42-261718d85258"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\r\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\r\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\r\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lRj1O88nURN",
    "outputId": "4784831c-0175-4510-f1b1-86b4c380c943"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCA_o5Dq0Tlj"
   },
   "source": [
    "## Step 7: Predicting Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Js6Bh396o8M"
   },
   "source": [
    "Example : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0a1Fn7h57qy",
    "outputId": "929cc2d2-7a13-4099-b1cc-805299e311c3"
   },
   "outputs": [],
   "source": [
    "print(test_reviews.iloc[0])\r\n",
    "print(\"Sentiment Analysis is :\")\r\n",
    "print(\"Bad\" if y_test[0][0] == 1 else \"Good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "Oz-dWI4t6YWQ",
    "outputId": "8ecb0e07-684b-4333-b9de-f530f1d114c2"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[:1])\r\n",
    "print(y_pred)\r\n",
    "\"Bad\" if np.argmax(y_pred) == 0 else \"Good\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51h33iYk6oHc"
   },
   "source": [
    "Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1CUqm8w6tD3",
    "outputId": "5d51cebe-d29b-4beb-9562-850a62e4ed82"
   },
   "outputs": [],
   "source": [
    "print(test_reviews.iloc[1])\r\n",
    "print(\"Bad\" if y_test[1][0] == 1 else \"Good\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "W9PYXkSa671F",
    "outputId": "d4aa30b2-cc25-441a-faea-fdbd8a0c90e1"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[1:2])\r\n",
    "print(y_pred)\r\n",
    "\"Bad\" if np.argmax(y_pred) == 0 else \"Good\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nux33qb17OHb"
   },
   "source": [
    "Example 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipxPzF2U7RmR",
    "outputId": "9c608fdc-3625-4274-ee8c-2e30f16af142"
   },
   "outputs": [],
   "source": [
    "print(test_reviews.iloc[5])\r\n",
    "print(\"Bad\" if y_test[5][0] == 1 else \"Good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "m3G2i6R17VOi",
    "outputId": "7334eab1-debf-4831-ae1d-76ad47e41d80"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test[5:6])\r\n",
    "print(y_pred)\r\n",
    "\"Bad\" if np.argmax(y_pred) == 0 else \"Good\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyU_zml507Uc"
   },
   "source": [
    "## Step 8: Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhcZSOj-7fBZ"
   },
   "outputs": [],
   "source": [
    "# confusion matrix in sklearn\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from keras import backend as K\r\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "\r\n",
    "labels=['positive','negative']\r\n",
    "\r\n",
    "#Confusion Matrix and Classification Report\r\n",
    "#confusion matrix\r\n",
    "y_pred=model.predict(X_test)\r\n",
    "#y_pred = (y_pred > 0.5)\r\n",
    "\r\n",
    "#cm =confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\r\n",
    "#print(\"Confusion Matrix : \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2P-s7PoYSM9e",
    "outputId": "b5aaed97-bffe-4b51-bcbc-0097032961e1"
   },
   "outputs": [],
   "source": [
    "confusion_df = pd.DataFrame(confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1)),\r\n",
    "             columns=[\"Predicted Class \" + str(class_name) for class_name in [0,1]],\r\n",
    "             index = [\"Class \" + str(class_name) for class_name in [0,1]])\r\n",
    "\r\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "6XHV-I0gLkbm",
    "outputId": "69349372-c2a0-4ef9-f920-b62d5d816192"
   },
   "outputs": [],
   "source": [
    "f, ax=plt.subplots(figsize=(5,5))\r\n",
    "sns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\r\n",
    "plt.xlabel(\"y_pred\")\r\n",
    "plt.ylabel(\"y_true\")\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0NMUAipOWgY"
   },
   "source": [
    "## Step 9: Classification Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM1zmaUWNxlR"
   },
   "source": [
    "Precision Score <br>\r\n",
    "TP – True Positives <br>\r\n",
    "FP – False Positives<br>\r\n",
    "\r\n",
    "Precision – Accuracy of positive predictions. <br>\r\n",
    "Precision = TP/(TP + FP)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNqSWvVXNKn4",
    "outputId": "96d08c41-82ae-461d-b910-9e7f088e3165"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\r\n",
    "\r\n",
    "print(\"Precision score: {}\".format(precision_score(y_test.argmax(axis=1),y_pred.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoZzjsW5N8or"
   },
   "source": [
    "Recall Score <br>\r\n",
    "FN – False Negatives <br>\r\n",
    "\r\n",
    "Recall (aka sensitivity or true positive rate): <br>\r\n",
    "Fraction of positives That were correctly identified. <br>\r\n",
    "Recall = TP/(TP+FN) <br> \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2SgUtbVOCsa",
    "outputId": "6eba60ff-6f21-46a3-8360-fc1b35b48cf1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "print(\"Recall score: {}\".format(recall_score(y_test.argmax(axis=1),y_pred.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thO41fUTPEdB"
   },
   "source": [
    "F1 Score <br>\r\n",
    "F1 Score (aka F-Score or F-Measure) – A helpful metric for comparing two classifiers. F1 Score takes into account precision and the recall. It is created by finding the the harmonic mean of precision and recall.\r\n",
    "<br>\r\n",
    "F1 = 2 x (precision x recall)/(precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_qnx2GXPL8_",
    "outputId": "a5f484f8-390b-4183-cfbf-7786bde6ded7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\r\n",
    "\r\n",
    "print(\"F1 Score: {}\".format(f1_score(y_test.argmax(axis=1),y_pred.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99MG4ZbSPVX6"
   },
   "source": [
    "#### Classification Report\r\n",
    "Report which includes Precision, Recall and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaRksZmkPZDn",
    "outputId": "b2e0539b-a215-4a3f-e0a9-578d37efde84"
   },
   "outputs": [],
   "source": [
    "print(\"CLASSIFICATION REPORT: \\n\")\r\n",
    "cr = classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1))\r\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lwXGjCXQcUa"
   },
   "source": [
    "## Step 10: Conclusion\r\n",
    "\r\n",
    "\r\n",
    "1.   We started with analyzing and describing the data and providing a few metrics.\r\n",
    "2.   We then proceeded with data preprocessing and creating the word clouds for the positive and negative reviews.\r\n",
    "3.   We used the USE for word embeddings and tested our data with the Keras model.\r\n",
    "4.   We achieved an accuracy of 91% and 90% for the negative and positive reviews respectively.\r\n",
    "5.   The full confusion matrix and the classification reports are detailed as above.\r\n",
    "6.  We also checked few test data as well.\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JQ9cdJAFqRj"
   },
   "source": [
    "## Step 11: Reference:\r\n",
    "\r\n",
    "https://curiousily.com/posts/sentiment-analysis-with-tensorflow-2-and-keras-using-python/\r\n",
    "\r\n",
    "https://realpython.com/python-keras-text-classification/\r\n",
    "\r\n",
    "\r\n",
    "https://joshlawman.com/metrics-classification-report-breakdown-precision-recall-f1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MtoelDF0xo8"
   },
   "source": [
    "# Step 12: The END"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AG Final Assignment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}